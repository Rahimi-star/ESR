{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame,Series\n",
    "import imputation\n",
    "import cross_validate as scv\n",
    "import log_worker as slog\n",
    "import plotting as splt\n",
    "from model_analsyis import nested_cross_validation_analysis as ncv_analysis\n",
    "import evaluation as evaluate\n",
    "import mathx\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************** GLOBAL PARAMETERS ******************************************\n",
    "data_dir = os.path.join(os.getcwd(),'data')\n",
    "input_data_file = os.path.abspath('temp__mc80_imputed_normalized_2019-08-23.csv')\n",
    "output_dir = os.path.join(data_dir, 'interim')\n",
    "figure_dir = output_dir\n",
    "metrics_output_file = os.path.join(output_dir,'scoring_metrics.txt')\n",
    "store_prediction_probs = True\n",
    "prediction_prob_dir = os.path.join(output_dir, 'prediction_probabilities')\n",
    "selected_features_file = os.path.join(output_dir,'selected_features.txt')\n",
    "seed = 287462\n",
    "num_folds = 10  # number of stratified folds for outside loop\n",
    "shuffle_on_split = False  # shuffle data before splitting into folds\n",
    "# number of features for feature selection, recommended number positive examples in training/ 10\n",
    "# if set to -1 use all features\n",
    "num_features = -1\n",
    "date_string='2019-08-23'\n",
    "file_prefix='temp_'\n",
    "\n",
    "slog.log_items(\"Global Parameters\\n\", metrics_output_file,\n",
    "               num_folds=num_folds,\n",
    "               num_features=num_features,\n",
    "               shuffle_on_split=shuffle_on_split,\n",
    "               seed=seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ************************* GLOBAL PARAMETERS END *************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "cases= pd.read_csv(os.path.join(os.path.join(data_dir,'raw'),'CASE_FILE.csv'))\n",
    "\n",
    "controls = pd.read_csv(os.path.join(os.path.join(data_dir,'raw'),'CONTROL_FILE.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Preprocessing Section***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Section\n",
    "cols_to_drop = []\n",
    "\n",
    "# column names for features requiring normalization\n",
    "cols_to_norm = ['gest_age', 'age', 'wbc', 'hgb', 'it_ratio',\n",
    "       'capPH', 'bicarb', 'glucose', 'creatinine', 'platelet_count', 'hr',\n",
    "       'rr', 'temp', 'sbp', 'dbp', 'map', 'weight', 'fio2',\n",
    "       'hr_delta', 'rr_delta', 'mabp_delta',\n",
    "       'temp_delta']\n",
    "# Sepsis Groups\n",
    "# Group 1: Culture Positive sepsis: culture positive, minimum 5 days antibiotic treatment\n",
    "# Group 2: Negative Sepsis: Culture negative, <72 hours antibiotic treatment\n",
    "# Group 3: Clinical Sepsis: Culture negative, >120 hours of antibiotic treatment\n",
    "# sepsis groups to use in positive samples (cases):\n",
    "CASE_GRPS = [1,3]\n",
    "\n",
    "# control group data is from non-septic periods for same individuals in case groups\n",
    "# if using controls file with unspecified groups, set to None\n",
    "CONTROL_GRPS = None\n",
    "missing_cutoff = 80\n",
    "\n",
    "cases['sepsis'] = 1\n",
    "controls['sepsis'] = 0\n",
    "\n",
    "# select data from specified sepsis groups\n",
    "if CONTROL_GRPS is None:\n",
    "    controls['sepsis_group'] = -1\n",
    "    CONTROL_GRPS = [-1]\n",
    "X = pd.concat([cases[cases['sepsis_group'].isin(CASE_GRPS)],\n",
    "               controls[controls['sepsis_group'].isin(CONTROL_GRPS)]],sort=True)\n",
    "\n",
    "of = os.path.join(data_dir ,'case_control_stats.txt')\n",
    "slog.log_line(\"samples count: {0}\\n\".format(len(X)), of)\n",
    "y = X['sepsis']\n",
    "slog.log_line('target counts\\n{0}\\n'.format(y.value_counts()), of)\n",
    "slog.log_line('Incidence Rate (percent): {0:.3f}\\n'.format(100 * np.sum(y) / float(len(y))), of)\n",
    "\n",
    "# Imputation\n",
    "missing_percentages = imputation.missing_percents(X)\n",
    "slog.log_dictionary(missing_percentages, 'Missing Data Percentages\\n', False,\n",
    "                          os.path.join(data_dir ,'missing_data_percents.txt'))\n",
    "\n",
    "# drop columns with missing percentage over threshold\n",
    "#cols_to_drop = []\n",
    "for k,v in missing_percentages.items():\n",
    "    if v > missing_cutoff:\n",
    "        cols_to_drop.append(k)\n",
    "\n",
    "for c in cols_to_drop:\n",
    "    X = X.drop(c,axis=1)\n",
    "    if c in cols_to_norm:\n",
    "        cols_to_norm.remove(c)\n",
    "        \n",
    "        # impute missing values\n",
    "imp = Imputer(strategy='mean')\n",
    "Ximp = imp.fit_transform(X)\n",
    "cnames = X.columns\n",
    "X = pd.DataFrame(data=Ximp, columns=cnames)\n",
    "\n",
    "# Normalization\n",
    "X[cols_to_norm] = X[cols_to_norm].apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "## Store processed data\n",
    "X.to_csv('{0}_mc{1}_imputed_normalized_{2}.csv'.\n",
    "                      format(file_prefix,missing_cutoff,date_string), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Trian and validate MODELS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import preprocessd data\n",
    "all_data = pd.read_csv(input_data_file).sample(frac=1, random_state=seed)\n",
    "y = all_data['sepsis']\n",
    "X = all_data.drop('sepsis', axis=1).drop('sepsis_group', axis=1)\n",
    "\n",
    "# Use stratified K-fold to get data split indices\n",
    "skf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=shuffle_on_split)\n",
    "folds = {}\n",
    "fold_idx = 0\n",
    "for train_split, test_split in skf.split(X,y):\n",
    "    folds[fold_idx] = test_split\n",
    "    fold_idx += 1\n",
    "\n",
    "# evaluate models\n",
    "kn = num_features\n",
    "if num_features == -1:\n",
    "    kn = len(X.columns)\n",
    "\n",
    "# wrapper method to enable passing a random state for scoring method of feature selector\n",
    "def seeded_mutual_info_classif(X, y):\n",
    "    return mutual_info_classif(X,y, random_state=seed)\n",
    "\n",
    "feature_selector = SelectKBest(seeded_mutual_info_classif, k=kn)\n",
    "\n",
    "if store_prediction_probs and not os.path.exists(prediction_prob_dir):\n",
    "    os.makedirs(prediction_prob_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 1 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 2 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 3 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 4 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 5 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 6 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 7 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 8 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 9 of 10 for LogisticRegression\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Logistic Regression\n",
      "accuracy:\tmean=0.780\tstd=0.030\trange=[0.707,0.818]\n",
      "f1:\tmean=0.640\tstd=0.040\trange=[0.566,0.703]\n",
      "sensitivity:\tmean=0.768\tstd=0.049\trange=[0.703,0.868]\n",
      "specificity:\tmean=0.784\tstd=0.035\trange=[0.691,0.809]\n",
      "precision:\tmean=0.549\tstd=0.041\trange=[0.452,0.604]\n",
      "ROC-AUC:\tmean=0.854\tstd=0.026\trange=[0.802,0.902]\n",
      "avg_precision:\tmean=0.707\tstd=0.047\trange=[0.585,0.760]\n",
      "npv:\tmean=0.908\tstd=0.018\trange=[0.889,0.946]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ************************* Model evaluations ****************************************\n",
    "# --------------------------   logistic regression --------------------------------------------\n",
    "parameter_candidates = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "model = LogisticRegression(penalty='l2',class_weight='balanced', random_state=seed)\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"Logistic Regression\", \"LR\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"LR_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"LR_targets.csv\"), seed=seed,\n",
    "             selected_features_file=selected_features_file,\n",
    "             feature_coefs_file=os.path.join(output_dir,\"LR_coefs.csv\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 1 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 2 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 3 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 4 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 5 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 6 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 7 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 8 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 9 of 10 for SVC\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "SVM (RBF)\n",
      "accuracy:\tmean=0.796\tstd=0.030\trange=[0.748,0.851]\n",
      "f1:\tmean=0.651\tstd=0.044\trange=[0.602,0.738]\n",
      "sensitivity:\tmean=0.749\tstd=0.052\trange=[0.676,0.842]\n",
      "specificity:\tmean=0.812\tstd=0.035\trange=[0.745,0.864]\n",
      "precision:\tmean=0.578\tstd=0.050\trange=[0.500,0.674]\n",
      "ROC-AUC:\tmean=0.867\tstd=0.025\trange=[0.826,0.921]\n",
      "avg_precision:\tmean=0.730\tstd=0.049\trange=[0.637,0.781]\n",
      "npv:\tmean=0.905\tstd=0.017\trange=[0.882,0.938]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------  support vector machine ----------------------------------------------\n",
    "parameter_candidates = [{'C': [0.01, 0.1, 1, 10, 100],\n",
    "                         'gamma': [0.01, 0.1, 1, 10, 100]}]\n",
    "model = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=seed)\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"SVM (RBF)\", \"SVM-RBF\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"SVM_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"SVM_targets.csv\"), seed=seed, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for GaussianNB\n",
      "Starting run 1 of 10 for GaussianNB\n",
      "Starting run 2 of 10 for GaussianNB\n",
      "Starting run 3 of 10 for GaussianNB\n",
      "Starting run 4 of 10 for GaussianNB\n",
      "Starting run 5 of 10 for GaussianNB\n",
      "Starting run 6 of 10 for GaussianNB\n",
      "Starting run 7 of 10 for GaussianNB\n",
      "Starting run 8 of 10 for GaussianNB\n",
      "Starting run 9 of 10 for GaussianNB\n",
      "Starting run 0 of 10 for GaussianNB\n",
      "Starting run 1 of 10 for GaussianNB\n",
      "Starting run 2 of 10 for GaussianNB\n",
      "Starting run 3 of 10 for GaussianNB\n",
      "Starting run 4 of 10 for GaussianNB\n",
      "Starting run 5 of 10 for GaussianNB\n",
      "Starting run 6 of 10 for GaussianNB\n",
      "Starting run 7 of 10 for GaussianNB\n",
      "Starting run 8 of 10 for GaussianNB\n",
      "Starting run 9 of 10 for GaussianNB\n",
      "Naive Bayes\n",
      "accuracy:\tmean=0.809\tstd=0.009\trange=[0.796,0.824]\n",
      "f1:\tmean=0.527\tstd=0.048\trange=[0.408,0.594]\n",
      "sensitivity:\tmean=0.424\tstd=0.066\trange=[0.270,0.526]\n",
      "specificity:\tmean=0.941\tstd=0.022\trange=[0.900,0.982]\n",
      "precision:\tmean=0.720\tstd=0.058\trange=[0.640,0.833]\n",
      "ROC-AUC:\tmean=0.846\tstd=0.024\trange=[0.809,0.896]\n",
      "avg_precision:\tmean=0.645\tstd=0.043\trange=[0.555,0.699]\n",
      "npv:\tmean=0.828\tstd=0.013\trange=[0.800,0.846]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  --------------------------  Gaussian NB -------------------------------------------------------\n",
    "model = GaussianNB()\n",
    "metric_values, fpr_scores, tpr_scores, precision_scores, recall_scores = \\\n",
    "   scv.nested_cross_validate(model, None, folds, X, y, feature_selector=feature_selector)\n",
    "ncv_analysis(model, None, folds, X, y, feature_selector, \"Naive Bayes\", \"NaiveBayes\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"NaiveBayes_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"NaiveBayes_targets.csv\"), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for GaussianProcessClassifier\n",
      "Starting run 1 of 10 for GaussianProcessClassifier\n",
      "Starting run 2 of 10 for GaussianProcessClassifier\n",
      "Starting run 3 of 10 for GaussianProcessClassifier\n",
      "Starting run 4 of 10 for GaussianProcessClassifier\n",
      "Starting run 5 of 10 for GaussianProcessClassifier\n",
      "Starting run 6 of 10 for GaussianProcessClassifier\n",
      "Starting run 7 of 10 for GaussianProcessClassifier\n",
      "Starting run 8 of 10 for GaussianProcessClassifier\n",
      "Starting run 9 of 10 for GaussianProcessClassifier\n",
      "Starting run 0 of 10 for GaussianProcessClassifier\n",
      "Starting run 1 of 10 for GaussianProcessClassifier\n",
      "Starting run 2 of 10 for GaussianProcessClassifier\n",
      "Starting run 3 of 10 for GaussianProcessClassifier\n",
      "Starting run 4 of 10 for GaussianProcessClassifier\n",
      "Starting run 5 of 10 for GaussianProcessClassifier\n",
      "Starting run 6 of 10 for GaussianProcessClassifier\n",
      "Starting run 7 of 10 for GaussianProcessClassifier\n",
      "Starting run 8 of 10 for GaussianProcessClassifier\n",
      "Starting run 9 of 10 for GaussianProcessClassifier\n",
      "Gaussian Process\n",
      "accuracy:\tmean=0.799\tstd=0.021\trange=[0.764,0.824]\n",
      "f1:\tmean=0.462\tstd=0.060\trange=[0.346,0.536]\n",
      "sensitivity:\tmean=0.341\tstd=0.052\trange=[0.243,0.432]\n",
      "specificity:\tmean=0.955\tstd=0.021\trange=[0.909,0.982]\n",
      "precision:\tmean=0.725\tstd=0.098\trange=[0.565,0.875]\n",
      "ROC-AUC:\tmean=0.790\tstd=0.031\trange=[0.749,0.832]\n",
      "avg_precision:\tmean=0.603\tstd=0.083\trange=[0.486,0.711]\n",
      "npv:\tmean=0.810\tstd=0.013\trange=[0.788,0.831]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  --------------------------  Gaussian Process -------------------------------------------\n",
    "model = GaussianProcessClassifier(random_state = seed)\n",
    "metric_values, fpr_scores, tpr_scores, precision_scores, recall_scores = \\\n",
    "    scv.nested_cross_validate(model, None, folds, X, y, feature_selector=feature_selector)\n",
    "ncv_analysis(model, None, folds, X, y, feature_selector, \"Gaussian Process\", \"GaussianProcess\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"GaussianProcess_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"GaussianProcess_targets.csv\"), seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 1 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 2 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 3 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 4 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 5 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 6 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 7 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 8 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 9 of 10 for RandomForestClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Random Forest\n",
      "accuracy:\tmean=0.806\tstd=0.028\trange=[0.776,0.851]\n",
      "f1:\tmean=0.622\tstd=0.062\trange=[0.543,0.711]\n",
      "sensitivity:\tmean=0.634\tstd=0.086\trange=[0.514,0.730]\n",
      "specificity:\tmean=0.865\tstd=0.032\trange=[0.791,0.900]\n",
      "precision:\tmean=0.616\tstd=0.058\trange=[0.540,0.711]\n",
      "ROC-AUC:\tmean=0.863\tstd=0.021\trange=[0.821,0.902]\n",
      "avg_precision:\tmean=0.707\tstd=0.059\trange=[0.612,0.773]\n",
      "npv:\tmean=0.875\tstd=0.024\trange=[0.842,0.900]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  --------------------------  Random Forest --------------------------------------------\n",
    "parameter_candidates = [{'n_estimators': [10, 50, 100, 200],\n",
    "                         'criterion': ['gini','entropy'],\n",
    "                         'max_depth': [2, 4, 6]}]\n",
    "model = RandomForestClassifier(random_state=seed, class_weight='balanced')\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"Random Forest\", \"RandomForest\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"RandomForest_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"RandomForest_targets.csv\"), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for AdaBoostClassifier\n",
      "\tStarting grid search ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-3dea53493e9c>\", line 11, in <module>\n",
      "    os.path.join(prediction_prob_dir, \"AdaBoost_targets.csv\"), seed=seed)\n",
      "  File \"C:\\Users\\RR\\Documents\\Python Scripts\\sepsis\\model_analsyis.py\", line 32, in nested_cross_validation_analysis\n",
      "    feature_coefs_file=feature_coefs_file)\n",
      "  File \"C:\\Users\\RR\\Documents\\Python Scripts\\sepsis\\cross_validate.py\", line 97, in nested_cross_validate\n",
      "    gs.fit(X_cv, y_cv)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 687, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1148, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 666, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 924, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\", line 427, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\", line 150, in fit\n",
      "    random_state)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\", line 486, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\", line 498, in _boost_real\n",
      "    y_predict_proba = estimator.predict_proba(X)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 626, in _predict_proba\n",
      "    return pred_proba(X)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 674, in _dense_predict_proba\n",
      "    cache_size=self.cache_size, coef0=self.coef0, gamma=self._gamma)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"J:\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"J:\\Anaconda3\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"J:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"J:\\Anaconda3\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"J:\\Anaconda3\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"J:\\Anaconda3\\lib\\tokenize.py\", line 447, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "#  --------------------------  AdaBoost -------------------------------------------------\n",
    "parameter_candidates = [{'base_estimator': [DecisionTreeClassifier(),\n",
    "                                            LogisticRegression(class_weight='balanced', random_state=seed),\n",
    "                                            SVC(kernel='rbf', probability=True,class_weight='balanced', random_state=seed)],\n",
    "                         'n_estimators': [50, 100],\n",
    "                         'learning_rate': [1.0, 0.5, 0.1]}]\n",
    "model = AdaBoostClassifier(random_state=seed)\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"AdaBoost\", \"AdaBoost\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"AdaBoost_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"AdaBoost_targets.csv\"), seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 1 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 2 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 3 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 4 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 5 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 6 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 7 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 8 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 9 of 10 for KNeighborsClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "KNN\n",
      "accuracy:\tmean=0.806\tstd=0.012\trange=[0.789,0.831]\n",
      "f1:\tmean=0.444\tstd=0.047\trange=[0.375,0.526]\n",
      "sensitivity:\tmean=0.307\tstd=0.046\trange=[0.237,0.405]\n",
      "specificity:\tmean=0.976\tstd=0.015\trange=[0.955,1.000]\n",
      "precision:\tmean=0.826\tstd=0.088\trange=[0.714,1.000]\n",
      "ROC-AUC:\tmean=0.793\tstd=0.034\trange=[0.743,0.840]\n",
      "avg_precision:\tmean=0.650\tstd=0.048\trange=[0.562,0.713]\n",
      "npv:\tmean=0.805\tstd=0.010\trange=[0.790,0.827]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  --------------------------  KNN Classifier ---------------------------------------\n",
    "parameter_candidates = [{'n_neighbors': [5, 10],\n",
    "                         'weights': ['uniform', 'distance']}]\n",
    "model = KNeighborsClassifier()\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"KNN\", \"KNN\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"KNN_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"KNN_targets.csv\"), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 1 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 2 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 3 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 4 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 5 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 6 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 7 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 8 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Starting run 9 of 10 for GradientBoostingClassifier\n",
      "\tStarting grid search ....\n",
      "\tGrid search complete ....\n",
      "Gradient Boost\n",
      "accuracy:\tmean=0.827\tstd=0.024\trange=[0.789,0.865]\n",
      "f1:\tmean=0.604\tstd=0.061\trange=[0.516,0.706]\n",
      "sensitivity:\tmean=0.523\tstd=0.079\trange=[0.421,0.676]\n",
      "specificity:\tmean=0.931\tstd=0.028\trange=[0.873,0.973]\n",
      "precision:\tmean=0.727\tstd=0.081\trange=[0.607,0.864]\n",
      "ROC-AUC:\tmean=0.870\tstd=0.025\trange=[0.815,0.903]\n",
      "avg_precision:\tmean=0.728\tstd=0.062\trange=[0.613,0.818]\n",
      "npv:\tmean=0.852\tstd=0.021\trange=[0.824,0.889]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------  Gradient Boosting -------------------------------------------\n",
    "# wrapper class to fix sklearn bug\n",
    "class init:\n",
    "    def __init__(self, est):\n",
    "        self.est = est\n",
    "    def predict(self, X):\n",
    "        return self.est.predict_proba(X)[:,1][:,np.newaxis]\n",
    "    def fit(self, X, y, *kwarg):\n",
    "        self.est.fit(X, y)\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=seed)\n",
    "parameter_candidates = [{'n_estimators': [50, 100, 200],\n",
    "                         'max_depth': [3, 5, 10],\n",
    "                         # 'init': [None,\n",
    "                         #          init(DecisionTreeClassifier(class_weight='balanced')),\n",
    "                         #          init(LogisticRegression(class_weight='balanced', random_state=seed)),\n",
    "                         #          init(SVC(kernel='rbf', probability=True,class_weight='balanced'))]\n",
    "                         }\n",
    "                        ]\n",
    "ncv_analysis(model, parameter_candidates, folds, X, y, feature_selector, \"Gradient Boost\", \"GradBoost\",\n",
    "             figure_dir, metrics_output_file, store_prediction_probs,\n",
    "             os.path.join(prediction_prob_dir, \"GradBoost_pred_probs.csv\"),\n",
    "             os.path.join(prediction_prob_dir, \"GradBoost_targets.csv\"), seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Postprocessing section***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\RR\\\\Documents\\\\Python Scripts\\\\sepsis\\\\data\\\\results\\\\PATH/TO/PREDICTION/PROBABILITES/FILE\\\\prediction_probabilities\\\\AdaBoost_pred_probs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0383c487c52e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_prefixes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m    \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaddata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prob_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m    \u001b[0mtargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaddata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_targ_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m    \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_metric_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_metric_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-0383c487c52e>\u001b[0m in \u001b[0;36mloaddata\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ************************* GLOBAL PARAMETERS END *************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloaddata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m    \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m        \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\RR\\\\Documents\\\\Python Scripts\\\\sepsis\\\\data\\\\results\\\\PATH/TO/PREDICTION/PROBABILITES/FILE\\\\prediction_probabilities\\\\AdaBoost_pred_probs.csv'"
     ]
    }
   ],
   "source": [
    " # Postprocessing section\n",
    "   \n",
    "   \n",
    "  #  ************************** GLOBAL PARAMETERS ******************************************\n",
    "data_dir = os.path.join(os.getcwd(),'data')\n",
    "\n",
    "input_data_dir = os.path.join(data_dir, \"results\",\n",
    "                              \"PATH/TO/PREDICTION/PROBABILITES/FILE\",\n",
    "                              \"prediction_probabilities\")\n",
    "\n",
    "\n",
    "_prob_file = os.path.join(input_data_dir,\"{0}_pred_probs.csv\")\n",
    "_targ_file = os.path.join(input_data_dir,\"{0}_targets.csv\")\n",
    "file_prefixes = ['AdaBoost', 'GradBoost','GaussianProcess', 'KNN', 'LR', 'NaiveBayes', 'RandomForest', 'SVM']\n",
    "target_metric_name = evaluate.SENSITIVITY\n",
    "target_metric_value = 0.8\n",
    "ci_level = 0.95\n",
    "metrics_output_file = os.path.join(data_dir, 'interim', 'scoring_metrics_fixed_{0}_{1}.csv'.\n",
    "                                   format(target_metric_name,target_metric_value))\n",
    "\n",
    "metrics_ranges_output_file = os.path.join(data_dir, 'interim', 'scoring_metrics_ranges_fixed_{0}_{1}.csv'.\n",
    "                                   format(target_metric_name,target_metric_value))\n",
    "# ************************* GLOBAL PARAMETERS END *************************************\n",
    "def loaddata(file):\n",
    "    with open(file,'r') as f:\n",
    "        all_data = []\n",
    "        for line in f.readlines():\n",
    "            data = [float(x) for x in line.split(\",\")]\n",
    "            all_data.append(data)\n",
    "        return all_data\n",
    "\n",
    "line = \"model,acc,acc_std,acc_cil,acc_cih,f1,f1_std,f1_cil,f1_cih,sensitivity,sensitivity_std,sensitivity_cil,sensitivity_cih,\" \\\n",
    "       \"specificity,specificity_std,specificity_cil,specificity_cih,precision,precision_std,precision_cil,precision_cih,\" \\\n",
    "       \"npv,npv_std,npv_cil,npv_cih\\n\"\n",
    "slog.log_line(line, metrics_output_file)\n",
    "\n",
    "range_line = \"model,acc,acc_low,acc_high,f1,f1_low,f1_high,sensitivity,sensitivity_low,sensitivity_high,\" \\\n",
    "       \"specificity,specificity_low,specificity_high,precision,precision_low,precision_high,\" \\\n",
    "       \"npv,npv_low,npv_high\\n\"\n",
    "slog.log_line(range_line, metrics_ranges_output_file)\n",
    "\n",
    "for fp in file_prefixes:\n",
    "    probs = loaddata(_prob_file.format(fp))\n",
    "    targs = loaddata(_targ_file.format(fp))\n",
    "    acc, f1, sen, spec, precis, npv = evaluate.compute_metrics(targs, probs, target_metric_value, target_metric_name)\n",
    "    scores = [acc, f1, sen, spec, precis, npv]\n",
    "    line = \"{0},\".format(fp)\n",
    "    range_line = \"{0},\".format(fp)\n",
    "    for score in scores:\n",
    "        m, s, cil, cih = mathx.mean_confidence_interval(score, ci_level)\n",
    "        line=\"{0}{1},{2},{3},{4},\".format(line, m,s,cil,cih)\n",
    "        low = np.min(score)\n",
    "        high = np.max(score)\n",
    "        range_line=\"{0}{1},{2},{3},\".format(range_line, m, low, high)\n",
    "    line = \"{0}\\n\".format(line[0:-1])\n",
    "    range_line=\"{0}\\n\".format(range_line[0:-1])\n",
    "    slog.log_line(line, metrics_output_file)\n",
    "    slog.log_line(range_line, metrics_ranges_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
